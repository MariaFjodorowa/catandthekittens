{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import LSTM, TimeDistributed, Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, Dropout\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corp = open('history.conll', encoding='utf-8').read()\n",
    "\n",
    "from conllu import parse, parse_tree\n",
    "from conllu import print_tree\n",
    "\n",
    "tree = parse(corp)\n",
    "\n",
    "import re\n",
    "p = re.compile('[а-яА-ЯёЁ]')\n",
    "p1=re.compile('[0-9]')\n",
    "\n",
    "lemmas=[]\n",
    "for i in tree:\n",
    "    for j in i:\n",
    "        if p.search(j['lemma']) and not p1.search(j['lemma']):\n",
    "            lemmas.append(j['lemma'].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "\n",
    "def generate_seq(model, tokenizer, max_length, seed_text, n_words):\n",
    "    in_text = seed_text\n",
    "    for _ in range(n_words):\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
    "        yhat = model.predict_classes(encoded, verbose=0)\n",
    "        out_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == yhat:\n",
    "                out_word = word\n",
    "                break\n",
    "        in_text += ' ' + out_word\n",
    "    return in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 8134\n",
      "Total Sequences: 64202\n",
      "Max Sequence Length: 2\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([' '.join(i for i in lemmas)])\n",
    "encoded = tokenizer.texts_to_sequences([' '.join(i for i in lemmas)])[0]\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocabulary Size: %d' % vocab_size)\n",
    "sequences = list()\n",
    "for i in range(2, len(encoded)):\n",
    "    sequence = encoded[i-1:i+1]\n",
    "    sequences.append(sequence)\n",
    "print('Total Sequences: %d' % len(sequences))\n",
    "max_length = max([len(seq) for seq in sequences])\n",
    "sequences = pad_sequences(sequences, maxlen=max_length, padding='pre')\n",
    "print('Max Sequence Length: %d' % max_length)\n",
    "sequences = array(sequences)\n",
    "X, y = sequences[:,:-1],sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 1, 10)             81340     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 50)                12200     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8134)              414834    \n",
      "=================================================================\n",
      "Total params: 508,374\n",
      "Trainable params: 508,374\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/75\n",
      "139s - loss: 7.5690 - acc: 0.0470\n",
      "Epoch 2/75\n",
      "143s - loss: 7.1808 - acc: 0.0494\n",
      "Epoch 3/75\n",
      "155s - loss: 7.0665 - acc: 0.0579\n",
      "Epoch 4/75\n",
      "148s - loss: 6.9562 - acc: 0.0626\n",
      "Epoch 5/75\n",
      "141s - loss: 6.8437 - acc: 0.0714\n",
      "Epoch 6/75\n",
      "144s - loss: 6.7199 - acc: 0.0785\n",
      "Epoch 7/75\n",
      "136s - loss: 6.5555 - acc: 0.0925\n",
      "Epoch 8/75\n",
      "138s - loss: 6.3808 - acc: 0.1072\n",
      "Epoch 9/75\n",
      "141s - loss: 6.2215 - acc: 0.1263\n",
      "Epoch 10/75\n",
      "143s - loss: 6.0799 - acc: 0.1382\n",
      "Epoch 11/75\n",
      "143s - loss: 5.9542 - acc: 0.1476\n",
      "Epoch 12/75\n",
      "135s - loss: 5.8390 - acc: 0.1574\n",
      "Epoch 13/75\n",
      "138s - loss: 5.7324 - acc: 0.1658\n",
      "Epoch 14/75\n",
      "140s - loss: 5.6334 - acc: 0.1711\n",
      "Epoch 15/75\n",
      "143s - loss: 5.5391 - acc: 0.1757\n",
      "Epoch 16/75\n",
      "139s - loss: 5.4521 - acc: 0.1822\n",
      "Epoch 17/75\n",
      "148s - loss: 5.3693 - acc: 0.1878\n",
      "Epoch 18/75\n",
      "142s - loss: 5.2925 - acc: 0.1917\n",
      "Epoch 19/75\n",
      "138s - loss: 5.2206 - acc: 0.1959\n",
      "Epoch 20/75\n",
      "136s - loss: 5.1527 - acc: 0.1996\n",
      "Epoch 21/75\n",
      "136s - loss: 5.0887 - acc: 0.2035\n",
      "Epoch 22/75\n",
      "137s - loss: 5.0284 - acc: 0.2083\n",
      "Epoch 23/75\n",
      "141s - loss: 4.9709 - acc: 0.2109\n",
      "Epoch 24/75\n",
      "141s - loss: 4.9174 - acc: 0.2135\n",
      "Epoch 25/75\n",
      "139s - loss: 4.8652 - acc: 0.2176\n",
      "Epoch 26/75\n",
      "139s - loss: 4.8170 - acc: 0.2198\n",
      "Epoch 27/75\n",
      "138s - loss: 4.7701 - acc: 0.2219\n",
      "Epoch 28/75\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length=max_length-1))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=75, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('lemmas_model2.h5')\n",
    "#model.save('lemmas_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model2=load_model('lemmas_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "взгляд на\n"
     ]
    }
   ],
   "source": [
    "#так генерируется наиболее вероятное следующеее слово\n",
    "print(generate_seq(model2, tokenizer, max_length-1, 'взгляд', 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#получаем матрицу вероятностей появления для всех известных модели слов после заданного н-грамма\n",
    "def get_all_probs(model, tokenizer, max_length, seed_text):\n",
    "    in_text = seed_text\n",
    "    encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "    encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
    "    yhat = model.predict(encoded, verbose=0)\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02563183,  0.04811867,  0.05004111,  0.1138985 ,  0.32530677], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(get_all_probs(model2, tokenizer, max_length-1, 'взгляд')[0])[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#генерируем строки на замену\n",
    "import nltk\n",
    "stop_words= nltk.corpus.stopwords.words('russian')\n",
    "inv_dict = {v: k for k, v in tokenizer.word_index.items()}\n",
    "from pymystem3 import Mystem\n",
    "m = Mystem()\n",
    "\n",
    "small=1e-10\n",
    "#give it lemmatized strings maybe\n",
    "def get_bigram(bigram_string):\n",
    "    suggestions=[]\n",
    "    #for string in trigram_strings:\n",
    "    prob=0.0\n",
    "    unigram=m.lemmatize(bigram_string[0])[0]\n",
    "    last_word=m.lemmatize(bigram_string[-1])[0]\n",
    "    prob_matrix=get_all_probs(model2, tokenizer, max_length-1, unigram)[0]\n",
    "    most_probable=np.sort(prob_matrix)[-200:]\n",
    "    if last_word in tokenizer.word_index.keys():\n",
    "        prob=prob_matrix[tokenizer.word_index[last_word]]\n",
    "    else:\n",
    "        prob=small\n",
    "    if prob not in most_probable and unigram not in stop_words:\n",
    "        for i in most_probable[-3:]:\n",
    "            ind=np.where(prob_matrix==i)[0][0]\n",
    "            next_word = inv_dict[ind]\n",
    "            if next_word not in stop_words:\n",
    "                suggestions.append(unigram +' '+next_word)\n",
    "    if suggestions:\n",
    "        return 'возможно неверная коллокация: {}, варианты замен: {}'.format(bigram_string, suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"возможно неверная коллокация: ['взгляд', 'православный'], варианты замен: ['взгляд николай']\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bigram(['взгляд', 'православный'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open('dict1.json','w',encoding='utf-8') as out:\n",
    "#     json.dump(tokenizer.word_index,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#тестируем\n",
    "test=open('бэд.txt', encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_text=[]\n",
    "for i in test.split():\n",
    "    i=i.lower()\n",
    "    if p.search(i) and not p1.search(i):\n",
    "        clean_text.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams=list(nltk.ngrams(clean_text,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"возможно неверная коллокация: ['всероссийский', 'умер'], варианты замен: ['всероссийский математика', 'всероссийский принц', 'всероссийский иерархичность', 'всероссийский вдова', 'всероссийский чрезвычайный']\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bigram(list(bigrams[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "возможно неверная коллокация: ['особое', 'значение'], варианты замен: ['особый положение', 'особый назначение', 'особый место', 'особый внимание', 'особый военный']\n",
      "возможно неверная коллокация: ['значение', 'приобретает'], варианты замен: ['значение второй']\n",
      "возможно неверная коллокация: ['приобретает', 'вопрос'], варианты замен: ['приобретать нормативный', 'приобретать особый']\n",
      "None\n",
      "возможно неверная коллокация: ['о', 'заговоре'], варианты замен: ['о бодуэн', 'о деятельность', 'о работа']\n",
      "возможно неверная коллокация: ['заговоре', 'против'], варианты замен: ['заговор ориентироваться', 'заговор разыскание', 'заговор сибирский', 'заговор шечкина', 'заговор бесовский']\n",
      "возможно неверная коллокация: ['против', 'павла'], варианты замен: ['против русский', 'против партизан', 'против ссср', 'против японец', 'против большевизм']\n",
      "возможно неверная коллокация: ['павла', 'император'], варианты замен: ['павел иванович', 'павел александрович', 'павел павлович', 'павел францевич', 'павел федорович']\n",
      "возможно неверная коллокация: ['император', 'всероссийский'], варианты замен: ['император наполеон', 'император выразительный', 'император тойерданк', 'император ромеев', 'император максимилиан']\n",
      "возможно неверная коллокация: ['всероссийский', 'умер'], варианты замен: ['всероссийский математика', 'всероссийский принц', 'всероссийский иерархичность', 'всероссийский вдова', 'всероссийский чрезвычайный']\n",
      "возможно неверная коллокация: ['умер', 'уже'], варианты замен: ['умирать борис', 'умирать вячеслав']\n",
      "None\n",
      "возможно неверная коллокация: ['раскрытой', 'смертью,'], варианты замен: ['раскрывать поставлять', 'раскрывать культурный', 'раскрывать резкий', 'раскрывать количественный', 'раскрывать деталь']\n",
      "None\n",
      "None\n",
      "None\n",
      "возможно неверная коллокация: ['бы', 'объяснить'], варианты замен: ['бы добавлять']\n",
      "возможно неверная коллокация: ['объяснить', 'подробности'], варианты замен: ['объяснять почему', 'объяснять внезапность', 'объяснять это', 'объяснять главный']\n",
      "возможно неверная коллокация: ['подробности', 'совершения'], варианты замен: ['подробность разделять', 'подробность родиться']\n",
      "возможно неверная коллокация: ['совершения', 'заговора.'], варианты замен: ['совершение никакой', 'совершение диверсия']\n",
      "возможно неверная коллокация: ['заговора.', 'мать'], варианты замен: ['заговор ориентироваться', 'заговор разыскание', 'заговор сибирский', 'заговор шечкина', 'заговор бесовский']\n",
      "None\n",
      "возможно неверная коллокация: ['и', 'отец'], варианты замен: ['и ф']\n",
      "None\n",
      "возможно неверная коллокация: ['были', 'фактически'], варианты замен: ['быть создавать', 'быть опубликовывать', 'быть использовать', 'быть назначать']\n",
      "возможно неверная коллокация: ['фактически', 'отстранены'], варианты замен: ['фактически право', 'фактически сразу', 'фактически балласт', 'фактически депортировать']\n",
      "возможно неверная коллокация: ['отстранены', 'от'], варианты замен: ['отстранять дружеский', 'отстранять обладать', 'отстранять отв', 'отстранять время', 'отстранять абсолютный']\n",
      "возможно неверная коллокация: ['от', 'воспитания'], варианты замен: ['от ноябрь', 'от июль', 'от национальный', 'от июнь']\n",
      "возможно неверная коллокация: ['воспитания', 'своего'], варианты замен: ['воспитание относить', 'воспитание причастность', 'воспитание мурманский', 'воспитание сводиться']\n"
     ]
    }
   ],
   "source": [
    "#np.sort(prob_matrix)[-100:]\n",
    "#most_probable[-5:]\n",
    "for i in range(30):\n",
    "    print(get_bigram(list(bigrams[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "возможно неверная коллокация: ['приобретает', 'вопрос'], варианты замен: ['приобретать нормативный', 'приобретать особый']\n",
      "None\n",
      "None\n",
      "возможно неверная коллокация: ['заговоре', 'против'], варианты замен: ['заговор сибирский', 'заговор шечкина', 'заговор бесовский']\n",
      "возможно неверная коллокация: ['против', 'павла'], варианты замен: ['против ссср', 'против японец', 'против большевизм']\n",
      "возможно неверная коллокация: ['павла', 'император'], варианты замен: ['павел павлович', 'павел францевич', 'павел федорович']\n",
      "возможно неверная коллокация: ['император', 'всероссийский'], варианты замен: ['император тойерданк', 'император ромеев', 'император максимилиан']\n",
      "возможно неверная коллокация: ['всероссийский', 'умер'], варианты замен: ['всероссийский иерархичность', 'всероссийский вдова', 'всероссийский чрезвычайный']\n",
      "None\n",
      "None\n",
      "возможно неверная коллокация: ['раскрытой', 'смертью,'], варианты замен: ['раскрывать резкий', 'раскрывать количественный', 'раскрывать деталь']\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "возможно неверная коллокация: ['объяснить', 'подробности'], варианты замен: ['объяснять это', 'объяснять главный']\n",
      "None\n",
      "возможно неверная коллокация: ['совершения', 'заговора.'], варианты замен: ['совершение диверсия']\n",
      "возможно неверная коллокация: ['заговора.', 'мать'], варианты замен: ['заговор сибирский', 'заговор шечкина', 'заговор бесовский']\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "возможно неверная коллокация: ['фактически', 'отстранены'], варианты замен: ['фактически балласт', 'фактически депортировать']\n",
      "возможно неверная коллокация: ['отстранены', 'от'], варианты замен: ['отстранять отв', 'отстранять время', 'отстранять абсолютный']\n",
      "None\n",
      "возможно неверная коллокация: ['воспитания', 'своего'], варианты замен: ['воспитание причастность', 'воспитание мурманский', 'воспитание сводиться']\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    print(get_bigram(list(bigrams[i])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
