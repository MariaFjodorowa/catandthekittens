{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from conllu import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('введение', 'S'), ('поляризацией', 'S'), ('традиции', 'S'), ('было', 'V'), ('называть', 'V'), ('свойство', 'S'), ('языковых', 'S'), ('единиц', 'S'), ('заключается', 'V'), ('невозможности', 'S')]\n"
     ]
    }
   ],
   "source": [
    "p = re.compile('[а-яА-ЯёЁ]')\n",
    "f = open('../marked/linguistics.conll', encoding='utf-8')\n",
    "data = f.read()\n",
    "tree = parse(data)\n",
    "words=[]\n",
    "words_only=[]\n",
    "for i in tree:\n",
    "    for j in i:\n",
    "        if j['form']!='_' and j['form'].isalpha() and (j['upostag']=='S' or j['upostag']=='V') and p.search(j['form']) and j['form'] not in '[]\\/':\n",
    "            for w in j['form'].lower().split():\n",
    "                words.append((w, j['upostag']))\n",
    "                words_only.append(w)\n",
    "print(words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('linguistics_collocation_counts.xlsx','bigrams')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('строить', 'V'), ('помнится', 'V')), (('валентность', 'S'), ('говорится', 'V')), (('говорит', 'V'), ('дается', 'V')), (('может', 'V'), ('стимул', 'S')), (('степашина', 'S'), ('был', 'V')), (('половины', 'S'), ('задач', 'S')), (('оркестрион', 'S'), ('получают', 'V')), (('явление', 'S'), ('стороны', 'S')), (('результате', 'S'), ('журналистом', 'S')), (('искандер', 'S'), ('проверив', 'V'))]\n"
     ]
    }
   ],
   "source": [
    "pairs = set()\n",
    "coll = df['ngram'].tolist()\n",
    "len_words_2 = len(words)//2\n",
    "coll_tags = df['tag'].tolist()\n",
    "good_bigrams = []\n",
    "good_tags = []\n",
    "for i in range(len(coll)):\n",
    "    pair = coll[i].split()\n",
    "    pair_tags = coll_tags[i].split()\n",
    "    if (pair_tags[0]=='S' or pair_tags[0]=='V') and (pair_tags[1]=='S' or pair_tags[1]=='V') and len(pair[0])>1 and len(pair[1])>1:       \n",
    "        good_bigrams.append((pair[0],pair[1]))\n",
    "        good_tags.append((pair_tags[0],pair_tags[1]))\n",
    "    pairs.add((words[random.randrange(len_words_2)],words[random.randrange(len_words_2)]))\n",
    "bigrams = pairs - set(coll)\n",
    "bigrams = list(bigrams)\n",
    "print(bigrams[:10])\n",
    "bad_tags, bad_bigrams = [],[]\n",
    "for bigr in bigrams:\n",
    "    bad_tags.append((bigr[0][1], bigr[1][1]))\n",
    "    bad_bigrams.append((bigr[0][0], bigr[1][0]))\n",
    "len_good_bigrams = len(good_bigrams)\n",
    "bad_bigrams = bad_bigrams[:len_good_bigrams]\n",
    "bad_tags = bad_tags[:len_good_bigrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15194 15194\n",
      "                             bigrams  labels    tags\n",
      "0         (абессив, существительных)       1  (S, S)\n",
      "1          (абзаца, характеризуются)       1  (S, V)\n",
      "2                (абрахам, указывал)       1  (S, V)\n",
      "3                (абрахама, формами)       1  (S, S)\n",
      "4      (абстрактности, конкретности)       1  (S, S)\n",
      "5           (абсцисс, соответствуют)       1  (S, V)\n",
      "6                  (аванесов, пишет)       1  (S, V)\n",
      "7               (август, употреблял)       1  (S, V)\n",
      "8                  (автобуса, стоял)       1  (S, V)\n",
      "9              (автомобиль, потерял)       1  (S, V)\n",
      "10         (автопереводе, прибегает)       1  (S, V)\n",
      "11               (автор, апеллирует)       1  (S, V)\n",
      "12                     (автор, было)       1  (S, V)\n",
      "13                    (автор, видит)       1  (S, V)\n",
      "14                 (автор, выделяет)       1  (S, V)\n",
      "15                 (автор, выражает)       1  (S, V)\n",
      "16                   (автор, данных)       1  (S, S)\n",
      "17                (автор, допускает)       1  (S, V)\n",
      "18                 (автор, игоревой)       1  (S, S)\n",
      "19               (автор, использует)       1  (S, V)\n",
      "20            (автор, наталкивается)       1  (S, V)\n",
      "21               (автор, обращается)       1  (S, V)\n",
      "22                (автор, оригинала)       1  (S, S)\n",
      "23                (автор, отказался)       1  (S, V)\n",
      "24                 (автор, открытия)       1  (S, S)\n",
      "25                 (автор, отмечает)       1  (S, V)\n",
      "26               (автор, показывает)       1  (S, V)\n",
      "27                (автор, посвящает)       1  (S, V)\n",
      "28               (автор, предлагает)       1  (S, V)\n",
      "29                 (автор, приводит)       1  (S, V)\n",
      "...                              ...     ...     ...\n",
      "30358                 (хочет, идиом)       0  (V, S)\n",
      "30359         (элемента, адвербиалы)       0  (S, S)\n",
      "30360           (взгляды, запретить)       0  (S, V)\n",
      "30361                  (языка, того)       0  (S, S)\n",
      "30362               (слога, заметим)       0  (S, V)\n",
      "30363          (танграммы, значения)       0  (S, S)\n",
      "30364                 (отношений, г)       0  (S, S)\n",
      "30365       (напоминает, количество)       0  (V, S)\n",
      "30366                 (часы, корпус)       0  (S, S)\n",
      "30367             (профессии, части)       0  (S, S)\n",
      "30368                 (атак, любить)       0  (S, V)\n",
      "30369             (сознания, версии)       0  (S, S)\n",
      "30370              (сторона, выводы)       0  (S, S)\n",
      "30371            (сводится, считать)       0  (V, V)\n",
      "30372    (пословица, прилагательное)       0  (S, S)\n",
      "30373          (устройство, дативом)       0  (S, S)\n",
      "30374              (шагает, эпизоды)       0  (V, S)\n",
      "30375     (эвиденциальности, мимику)       0  (S, S)\n",
      "30376                  (винчи, идти)       0  (S, V)\n",
      "30377         (слов, детализировать)       0  (S, V)\n",
      "30378               (классы, раздел)       0  (S, S)\n",
      "30379          (утверждает, сигнала)       0  (V, S)\n",
      "30380                   (д, порядок)       0  (S, S)\n",
      "30381                  (х, занимают)       0  (S, V)\n",
      "30382       (карточки, исследование)       0  (S, S)\n",
      "30383             (автору, созданию)       0  (S, S)\n",
      "30384                (служит, толпы)       0  (V, S)\n",
      "30385     (существительному, отбора)       0  (S, S)\n",
      "30386         (вернуть, коннектором)       0  (V, S)\n",
      "30387            (булгаков, словарь)       0  (S, S)\n",
      "\n",
      "[30388 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "labels_good, labels_bad = [1 for c in good_bigrams], [0 for b in bad_bigrams]\n",
    "print(len(labels_good), len(labels_bad))\n",
    "train_test_data = pd.DataFrame(\n",
    "{\n",
    "    'bigrams':good_bigrams+bad_bigrams,\n",
    "    'tags':good_tags+bad_tags,\n",
    "    'labels':labels_good + labels_bad\n",
    "})\n",
    "print(train_test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_data.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_weirdness(lemmas_counts,contrast_lemmas_counts,flag):\n",
    "    Ts, Tg = sum(lemmas_counts.values()), sum(contrast_lemmas_counts.values())\n",
    "    weirdnesses = defaultdict(float)\n",
    "    for key in lemmas_counts.keys():\n",
    "        Ws, Wg = lemmas_counts[key], contrast_lemmas_counts[key]\n",
    "        weirdnesses[key] = (Ws/Ts)/((Wg+Ws)/(Tg+Ts))\n",
    "    result = sorted(weirdnesses.items(), key=lambda k_v: k_v[1], reverse=True)\n",
    "    with open('result_{0}grams.txt'.format(flag),'w',encoding='utf-8') as res:\n",
    "        for item in result:\n",
    "            res.write(str(item)+'\\r\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lemmas_counts = Counter(words_only)\n",
    "contrast_lemmas = []\n",
    "with open('corpus_analyzed_1.txt', 'r', encoding='utf-8') as contrast_corpus:\n",
    "    for line in contrast_corpus:\n",
    "        line = line.strip()\n",
    "        splitted = line.split(\"\\t\")\n",
    "        if len(splitted) > 1:\n",
    "            contrast_lemmas.append(splitted[0])\n",
    "contrast_lemmas_counts = Counter(contrast_lemmas)\n",
    "flag = 'uni'  # униграммы\n",
    "count_weirdness(lemmas_counts, contrast_lemmas_counts, flag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
